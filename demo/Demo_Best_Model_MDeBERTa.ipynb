{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## CÃ i Ä‘áº·t thÆ° viá»‡n"
      ],
      "metadata": {
        "id": "iCVIcvcj4-gt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u72rXQdXRgip",
        "outputId": "ea2d651c-9dc2-4727-f835-3c1a397fb4b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaneCmG0WadZ",
        "outputId": "6907eee1-ac78-4a76-eef1-bcb2e59405a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HÃ m tiá»n xá»­ lÃ½"
      ],
      "metadata": {
        "id": "p6P-Q5Kg5Gc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"\n",
        "        u\"\\U0001F300-\\U0001F5FF\"\n",
        "        u\"\\U0001F680-\\U0001F6FF\"\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "        u\"\\U00002500-\\U00002BEF\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"\n",
        "        u\"\\u3030\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "def remove_emoticons(text):\n",
        "    emoticon_pattern = re.compile(r'(:\\)+|:\\(+|=+\\)+|:v|:V|:\\||:D|:\\>|\\:<|:3|:P|:p|:o|:O|:s|:S|:x|:X|:â€™\\(|:\")')\n",
        "    return emoticon_pattern.sub('', text)\n",
        "\n",
        "def clean_text_basic(text):\n",
        "    text = re.sub(r'@(?:[A-ZÃ€-á»´][a-zÃ -á»¹]*\\s?)+,?', '', text)  # remove tags\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", '', text)                 # remove links\n",
        "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)                 # limit repeated characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()                   # normalize whitespace\n",
        "    return text"
      ],
      "metadata": {
        "id": "C5QCZ0oMy-0u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HÃ m chuáº©n hÃ³a teencode\n",
        "teencode_dict = {\n",
        "    \"t\" : \"tÃ´i\",\n",
        "    \"tao\" : \"tÃ´i\",\n",
        "    \"tui\" : \"tÃ´i\",\n",
        "    \"m\" : \"mÃ y\",\n",
        "    \"K\" : \"khÃ´ng\",\n",
        "    \"k\" : \"khÃ´ng\",\n",
        "    \"ko\" : \"khÃ´ng\",\n",
        "    \"nhma\" : \"nhÆ°ng mÃ \",\n",
        "    \"b\" : \"báº¡n\",\n",
        "    \"h\" : \"giá»\",\n",
        "    \"z\" : \"váº­y\",\n",
        "    \"zá»‹\" : \"váº­y\",\n",
        "    \"v\" : \"váº­y\",\n",
        "    \"ng\" : \"ngÆ°á»i\",\n",
        "    \"ngta\" : \"ngÆ°á»i ta\",\n",
        "    \"mn\" : \"má»i ngÆ°á»i\",\n",
        "    \"ms\" : \"má»›i\",\n",
        "    \"dc\" : \"Ä‘Æ°á»£c\",\n",
        "    \"Ä‘c\" : \"Ä‘Æ°á»£c\",\n",
        "    \"r\" : \"rá»“i\",\n",
        "    \"bl\" : \"bÃ¬nh luáº­n\",\n",
        "    \"vk\" : \"vá»£\",\n",
        "    \"ck\" : \"chá»“ng\",\n",
        "    \"thg\" : \"tháº±ng\",\n",
        "    \"CA\" : \"cÃ´ng an\",\n",
        "    \"e\" : \"em\",\n",
        "    \"vs\" : \"vá»›i\",\n",
        "    \"ae\" : \"anh em\",\n",
        "    \"ntn\" : \"nhÆ° tháº¿ nÃ y\",\n",
        "    \"bt\" : \"biáº¿t\",\n",
        "    \"j\" : \"gÃ¬\",\n",
        "    \"cgi\" : \"cÃ¡i gÃ¬\",\n",
        "    \"fb\" : \"facebook\",\n",
        "    \"cmt\" : \"bÃ¬nh luáº­n\",\n",
        "    \"tks\" : \"cáº£m Æ¡n\",\n",
        "    \"dt\" : \"dÃ¢n tá»™c\",\n",
        "    \"vn\" : \"Viá»‡t Nam\",\n",
        "    \"VN\" : \"Viá»‡t Nam\",\n",
        "    \"sg\" : \"ThÃ nh phá»‘ Há»“ ChÃ­ Minh\",\n",
        "    \"xh\" : \"xÃ£ há»™i\",\n",
        "    \"m\" : \"mÃ y\",\n",
        "    \"bn\" : \"báº¡n\",\n",
        "    \"a\" : \"anh\",\n",
        "    \"e\": \"em\",\n",
        "    \"mk\": \"mÃ¬nh\",\n",
        "    \"mik\": \"mÃ¬nh\",\n",
        "    \"ngkh\": \"ngÆ°á»i khÃ¡c\",\n",
        "    \"mxh\" : \"máº¡ng xÃ£ há»™i\",\n",
        "    \"gÄ‘\" : \"gia Ä‘Ã¬nh\",\n",
        "    \"Ä‘h\" : \"Äáº¡i há»c\",\n",
        "    \"Äh\" : \"Äáº¡i há»c\",\n",
        "    \"cntt\" : \"CÃ´ng nghá»‡ thÃ´ng tin\",\n",
        "    \"Cntt\" : \"CÃ´ng nghá»‡ thÃ´ng tin\",\n",
        "    \"auto\" : \"hiá»ƒn nhiÃªn\",\n",
        "    \"bro\" : \"anh em\",\n",
        "    \"thui\" : \"thÃ´i\",\n",
        "    \"tr\": \"trá»i\",\n",
        "    \"kcn\": \"kem chá»‘ng náº¯ng\",\n",
        "    \"sk\" : \"sá»©c khá»e\",\n",
        "    \"TQ\" : \"Trung Quá»‘c\",\n",
        "    \"máº¥y fen\" : \"cÃ¡c báº¡n\",\n",
        "    \"uk\" : \"á»«\",\n",
        "    \"Ä‘r\" : \"Ä‘Ãºng rá»“i\",\n",
        "    \"ykr\" : \"Ã½ kiáº¿n riÃªng\",\n",
        "    \"Ä‘v\" : \"Ä‘á»‘i vá»›i\",\n",
        "    \"rÃ²i\" : \"rá»“i\",\n",
        "    \"rÃ¹i\" : \"rá»“i\",\n",
        "    \"má»i ng\" : \"má»i ngÆ°á»i\",\n",
        "    \"hic\" : \"\",\n",
        "    \"huhu\" : \"\",\n",
        "    \"iu\": \"yÃªu\",\n",
        "    \"tÃ³p tÃ³p\": \"tiktok\",\n",
        "    \"záº­y\": \"váº­y\",\n",
        "    \"zá»“i\": \"rá»“i\",\n",
        "    \"hok\" : \"khÃ´ng\",\n",
        "    \"Æ¡i zá»i\" : \"Ã´i trá»i\",\n",
        "    \"zá»‹\" : \"váº­y\",\n",
        "    \"chj\" : \"chá»‹\",\n",
        "    \"zai\" : \"trai\",\n",
        "    \"SVÄ\" : \"sÃ¢n váº­n Ä‘á»™ng\",\n",
        "    \"HN\" : \"HÃ  Ná»™i\",\n",
        "    \"thk\" : \"tháº±ng\",\n",
        "    \"nc\" : \"nÆ°á»›c\",\n",
        "    \"vs\" : \"vá»›i\",\n",
        "    \"TÃ³pTÃ³p\" : \"TikTok\",\n",
        "    \"nhÃ¬u\" : \"nhiá»u\",\n",
        "    \"ng\" : \"ngÆ°á»i\",\n",
        "    \"p\" : \"phÃºt\",\n",
        "    \"bsÄ©\" : \"bÃ¡c sÄ©\",\n",
        "    \"hk\" : \"khÃ´ng\",\n",
        "    \"zui záº»\" : \"vui váº»\",\n",
        "    \"SV\" : \"sinh viÃªn\",\n",
        "    \"tá»i\" : \"tá»·\",\n",
        "    \"TPHCM\" : \"ThÃ nh phá»‘ Há»“ ChÃ­ Minh\",\n",
        "    \"GV\" : \"giÃ¡o viÃªn\",\n",
        "    \"cá»§\" : \"triá»‡u\",\n",
        "    \"Clb\" : \"cÃ¢u láº¡c bá»™\",\n",
        "    \"KHXH&NV\" : \"Khoa há»c xÃ£ há»™i vÃ  NhÃ¢n vÄƒn\",\n",
        "    \"dzá»‹\" : \"váº­y\",\n",
        "    \"GTVT\" : \"Giao thÃ´ng váº­n táº£i\",\n",
        "    \"lag\": \"giáº­t\",\n",
        "    \"Máº¹c\": \"Mercedes\",\n",
        "    \"ÄHQGHN\": \"Äáº¡i há»c Quá»‘c gia HÃ  Ná»™i\",\n",
        "    \"10k\": \"10 nghÃ¬n\",\n",
        "    \"ÄHQG TPHCM\": \"Äáº¡i há»c Quá»‘c gia ThÃ nh phá»‘ Há»“ ChÃ­ Minh\",\n",
        "    \"GDQP\": \"GiÃ¡o dá»¥c Quá»‘c phÃ²ng\",\n",
        "    \"info\": \"thÃ´ng tin\",\n",
        "    \"ÄH BKHN\": \"Äáº¡i há»c BÃ¡ch khoa HÃ  Ná»™i\",\n",
        "    \"KTX\": \"kÃ½ tÃºc xÃ¡\",\n",
        "    \"TDTT\": \"Thá»ƒ dá»¥c thá»ƒ thao\",\n",
        "    \"acc clone\": \"tÃ i khoáº£n phá»¥\",\n",
        "    \"spam\": \"tin rÃ¡c\",\n",
        "    \"update\": \"cáº­p nháº­t\",\n",
        "    \"content\": \"ná»™i dung\",\n",
        "    \"subs\": \"ngÆ°á»i theo dÃµi\",\n",
        "    \"template\": \"máº«u\",\n",
        "    \"text\": \"vÄƒn báº£n\",\n",
        "    \"newsfeed\": \"báº£ng tin\",\n",
        "    \"apply\": \"ná»™p Ä‘Æ¡n\",\n",
        "    \"N2\": \"trÃ¬nh Ä‘á»™ tiáº¿ng Nháº­t N2\",\n",
        "    \"Fresher\": \"ngÆ°á»i má»›i\",\n",
        "    \"skill\": \"ká»¹ nÄƒng\",\n",
        "    \"HR\": \"nhÃ¢n sá»±\",\n",
        "    \"TNCN\": \"thu nháº­p cÃ¡ nhÃ¢n\",\n",
        "    \"Outsource\": \"thuÃª ngoÃ i\",\n",
        "    \"networking\": \"xÃ¢y dá»±ng má»‘i quan há»‡\",\n",
        "    \"FMCG\": \"hÃ ng tiÃªu dÃ¹ng nhanh\",\n",
        "    \"OT\": \"tÄƒng ca\",\n",
        "    \"Broker\": \"mÃ´i giá»›i\",\n",
        "    \"ads\": \"quáº£ng cÃ¡o\",\n",
        "    \"kk\" : \"\",\n",
        "    \"BÄS\" : \"báº¥t Ä‘á»™ng sáº£n\"\n",
        "}\n",
        "\n",
        "def replace_teencode(text):\n",
        "    if not isinstance(text, str):\n",
        "        return text\n",
        "\n",
        "    sorted_dict = dict(sorted(teencode_dict.items(), key=lambda x: -len(x[0])))\n",
        "\n",
        "    for word, replacement in sorted_dict.items():\n",
        "        pattern = r'\\b' + re.escape(word) + r'\\b'\n",
        "        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
        "    return text"
      ],
      "metadata": {
        "id": "ihrYgKY88Wmm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HÃ m tiá»n xá»­ lÃ½ chÃ­nh\n",
        "def preprocess_claim(text):\n",
        "    text = remove_emoji(text)\n",
        "    text = remove_emoticons(text)\n",
        "    text = clean_text_basic(text)\n",
        "    text = replace_teencode(text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "LUu4DdwE8s9Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dá»± Ä‘oÃ¡n nhÃ£n"
      ],
      "metadata": {
        "id": "9GmwtDqQ5Kq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Load model Ä‘Ã£ fine-tuned\n",
        "model_path = \"/content/drive/MyDrive/fine_tuned_mdeberta_factcheck\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Äáº·t model sang cháº¿ Ä‘á»™ Ä‘Ã¡nh giÃ¡\n",
        "model.eval()\n",
        "\n",
        "def predict_fact_checking(claim: str, evidence: str):\n",
        "    \"\"\"\n",
        "    Dá»± Ä‘oÃ¡n nhÃ£n fact-checking tá»« má»™t cáº·p cÃ¢u claim vÃ  evidence.\n",
        "\n",
        "    Args:\n",
        "        claim (str): CÃ¢u tuyÃªn bá»‘ cáº§n kiá»ƒm tra.\n",
        "        evidence (str): CÃ¢u báº±ng chá»©ng Ä‘i kÃ¨m.\n",
        "\n",
        "    Returns:\n",
        "        Tuple chá»©a: nhÃ£n dá»± Ä‘oÃ¡n ('SUPPORTS' hoáº·c 'REFUTES') vÃ  xÃ¡c suáº¥t phÃ¢n lá»›p.\n",
        "    \"\"\"\n",
        "    # Tiá»n xá»­ lÃ½ claim\n",
        "    claim = preprocess_claim(claim)\n",
        "\n",
        "    # Tokenize Ä‘áº§u vÃ o\n",
        "    inputs = tokenizer(claim, evidence, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "    # Dá»± Ä‘oÃ¡n\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        pred_label = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "    # Mapping nhÃ£n\n",
        "    label_map = {0: \"SUPPORTS\", 1: \"REFUTES\"}\n",
        "    return label_map[pred_label], probs.squeeze().tolist()"
      ],
      "metadata": {
        "id": "fDZrhPlRV2Vy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VÃ­ dá»¥ 1\n",
        "claim = \"Viá»‡t Nam Ä‘Ã£ vÃ´ Ä‘á»‹ch SEA Games 32.\"\n",
        "evidence = \"SEA Games 32 Ä‘Æ°á»£c tá»• chá»©c táº¡i Campuchia, vÃ  ThÃ¡i Lan lÃ  Ä‘á»™i vÃ´ Ä‘á»‹ch bÃ³ng Ä‘Ã¡ nam.\"\n",
        "\n",
        "label, probabilities = predict_fact_checking(claim, evidence)\n",
        "\n",
        "print(f\"Claim: {claim}\")\n",
        "print(f\"Evidence: {evidence}\")\n",
        "print(f\"Predicted label: {label}\")\n",
        "print(f\"Probabilities (SUPPORTS, REFUTES): {probabilities}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4ndx8ubW94H",
        "outputId": "0a23ec89-2879-485a-c022-5795371c52f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claim: Viá»‡t Nam Ä‘Ã£ vÃ´ Ä‘á»‹ch SEA Games 32.\n",
            "Evidence: SEA Games 32 Ä‘Æ°á»£c tá»• chá»©c táº¡i Campuchia, vÃ  ThÃ¡i Lan lÃ  Ä‘á»™i vÃ´ Ä‘á»‹ch bÃ³ng Ä‘Ã¡ nam.\n",
            "Predicted label: REFUTES\n",
            "Probabilities (SUPPORTS, REFUTES): [0.0003420138673391193, 0.9996579885482788]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VÃ­ dá»¥ 2\n",
        "claim = \"@Linh Æ¡i mÃ y cÃ³ biáº¿t k??? Ä‘á»£t rá»“i ng ta phÃ¡t tiá»n há»— trá»£ 1tr8 cho sinh viÃªn khÃ³ khÄƒn z Ä‘Ã³ ðŸ˜®ðŸ˜® :)))\"\n",
        "evidence = \"NgÃ y 15/4/2025, ChÃ­nh phá»§ ban hÃ nh quyáº¿t Ä‘á»‹nh há»— trá»£ 1,8 triá»‡u Ä‘á»“ng cho má»—i sinh viÃªn cÃ³ hoÃ n cáº£nh khÃ³ khÄƒn.\"\n",
        "\n",
        "label, probabilities = predict_fact_checking(claim, evidence)\n",
        "\n",
        "print(f\"Claim: {claim}\")\n",
        "print(f\"Evidence: {evidence}\")\n",
        "print(f\"Predicted label: {label}\")\n",
        "print(f\"Probabilities (SUPPORTS, REFUTES): {probabilities}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9fCUz6jA0M4",
        "outputId": "0ea33d48-2447-430e-fac5-16281177964b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claim: @Linh Æ¡i mÃ y cÃ³ biáº¿t k??? Ä‘á»£t rá»“i ng ta phÃ¡t tiá»n há»— trá»£ 1tr8 cho sinh viÃªn khÃ³ khÄƒn z Ä‘Ã³ ðŸ˜®ðŸ˜® :)))\n",
            "Evidence: NgÃ y 15/4/2025, ChÃ­nh phá»§ ban hÃ nh quyáº¿t Ä‘á»‹nh há»— trá»£ 1,8 triá»‡u Ä‘á»“ng cho má»—i sinh viÃªn cÃ³ hoÃ n cáº£nh khÃ³ khÄƒn.\n",
            "Predicted label: SUPPORTS\n",
            "Probabilities (SUPPORTS, REFUTES): [0.9993643164634705, 0.0006357369711622596]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VÃ­ dá»¥ 3\n",
        "claim = \"Uá»‘ng nÆ°á»›c tÄƒng lá»±c bÃ² hÃºc cÃ³ háº¡i cho sá»©c khá»e náº¿u uá»‘ng lÃ¢u dÃ i Ä‘Ã³, @HoÃ i An Æ¡i, m bá»›t uá»‘ng láº¡i Ä‘i:(((\"\n",
        "evidence = \"CÃ¡c nghiÃªn cá»©u cho tháº¥y sá»­ dá»¥ng nÆ°á»›c tÄƒng lá»±c bÃ² hÃºc thÆ°á»ng xuyÃªn cÃ³ thá»ƒ dáº«n Ä‘áº¿n cÃ¡c váº¥n Ä‘á» tim máº¡ch vÃ  huyáº¿t Ã¡p do hÃ m lÆ°á»£ng caffeine vÃ  Ä‘Æ°á»ng cao.\"\n",
        "\n",
        "label, probabilities = predict_fact_checking(claim, evidence)\n",
        "\n",
        "print(f\"Claim: {claim}\")\n",
        "print(f\"Evidence: {evidence}\")\n",
        "print(f\"Predicted label: {label}\")\n",
        "print(f\"Probabilities (SUPPORTS, REFUTES): {probabilities}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPUGI7EKvyKy",
        "outputId": "a35eff15-5370-4fe0-d60f-ac99ac5c5683"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claim: Uá»‘ng nÆ°á»›c tÄƒng lá»±c bÃ² hÃºc cÃ³ háº¡i cho sá»©c khá»e náº¿u uá»‘ng lÃ¢u dÃ i Ä‘Ã³, @HoÃ i An Æ¡i, m bá»›t uá»‘ng láº¡i Ä‘i:(((\n",
            "Evidence: CÃ¡c nghiÃªn cá»©u cho tháº¥y sá»­ dá»¥ng nÆ°á»›c tÄƒng lá»±c bÃ² hÃºc thÆ°á»ng xuyÃªn cÃ³ thá»ƒ dáº«n Ä‘áº¿n cÃ¡c váº¥n Ä‘á» tim máº¡ch vÃ  huyáº¿t Ã¡p do hÃ m lÆ°á»£ng caffeine vÃ  Ä‘Æ°á»ng cao.\n",
            "Predicted label: SUPPORTS\n",
            "Probabilities (SUPPORTS, REFUTES): [0.9997296929359436, 0.0002703361096791923]\n"
          ]
        }
      ]
    }
  ]
}